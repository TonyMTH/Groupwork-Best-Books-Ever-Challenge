{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('best-books.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the awards col into num of awards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.head(50)\n",
    "df2 = df2.replace({'awards': {np.nan: 0}})\n",
    "\n",
    "d = []\n",
    "\n",
    "for i in df2.index:\n",
    "    if df2.loc[i, \"awards\"] == 0:\n",
    "        d.append(0)\n",
    "    else:\n",
    "        d.append( len( ast.literal_eval(df2.loc[i, \"awards\"]) ) )\n",
    "\n",
    "df2['awards length'] = d\n",
    "# df2['awards length'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_max = df2['avg_rating'].copy()\n",
    "def min_max_normalization(df_min_max):\n",
    "    df_min_max = 1 + (df_min_max - df_min_max.min()) / (df_min_max.max() - df_min_max.min()) * 9\n",
    "    return round(df_min_max, 2)\n",
    "\n",
    "minmax_norm_ratings = min_max_normalization(df_min_max)\n",
    "# print(minmax_norm_ratings)\n",
    "df2['minmax_norm_ratings'] = minmax_norm_ratings\n",
    "# print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalization(df_min_max):\n",
    "    df_min_max = 1 + (df_min_max - df_min_max.mean()) / (df_min_max.max() - df_min_max.min()) * 9\n",
    "    return round(df_min_max, 2)\n",
    "\n",
    "mean_norm_ratings = mean_normalization(df_min_max)\n",
    "df2['mean_norm_ratings'] = mean_norm_ratings\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort by minmax_norm_ratings Given Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_author(df, author):\n",
    "    df = df.loc[df.author == author]\n",
    "    df.sort_values(by=['minmax_norm_ratings'], ascending=[False])\n",
    "    return df\n",
    "\n",
    "# check_author(df2, 'J.K. Rowling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort by publishing year and get mean of minmax_norm_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('original_publish_year')['minmax_norm_ratings'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort by author and check who has highest average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('author')['minmax_norm_ratings'].mean().sort_values( ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort by genre and check ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO SEE HOW THIS BEHAVES WITH 3 VALUES=3 GENRES\n",
    "df2.groupby('genres')['minmax_norm_ratings'].mean().sort_values( ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort no of awards by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['awards length']\n",
    "df2.sort_values(by=['awards length', 'author'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort by minmax_norm_ratings Given Year of publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_year(df, year):\n",
    "    df = df.loc[df.original_publish_year == year]\n",
    "    df.sort_values(by=['minmax_norm_ratings'], ascending=[False])\n",
    "    return df\n",
    "\n",
    "# check_year(df2, 2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check if book series are rated better than non series books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('series')['minmax_norm_ratings'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS - check what place is more commonly reffered to in these books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           [District 12, Panem, Capitol, Panem, Panem]\n",
      "1     [Hogwarts School of Witchcraft and Wizardry, L...\n",
      "2                           [Maycomb, Alabama, Alabama]\n",
      "3        [United Kingdom, Derbyshire, England, England]\n",
      "4     [Forks, Washington, Phoenix, Arizona, Washingt...\n",
      "5                                   [Molching, Germany]\n",
      "6                             [England, United Kingdom]\n",
      "7                                     [London, England]\n",
      "8                                        [Middle-earth]\n",
      "9                    [Indianapolis, Indiana, Amsterdam]\n",
      "10                                   [Atlanta, Georgia]\n",
      "11                                                    0\n",
      "12                                                    0\n",
      "13                                                    0\n",
      "14                                            [England]\n",
      "15                     [Paris, London, England, France]\n",
      "16           [Thornfield Hall, England, United Kingdom]\n",
      "17                                       [Kyoto, Japan]\n",
      "18                [United Kingdom, England, Wonderland]\n",
      "19                                      [Paris, France]\n",
      "20                                                    0\n",
      "21                           [Pittsburgh, Pennsylvania]\n",
      "22                                  [Chicago, Illinois]\n",
      "23    [New York City, New York, New York (State), Lo...\n",
      "24    [London, England, Hogwarts School of Witchcraf...\n",
      "25                      [Egypt, Sahara Desert, Tangier]\n",
      "26                                                    0\n",
      "27    [Russian Empire, Saint Petersburg, Russian Emp...\n",
      "28                                      [Verona, Italy]\n",
      "29                                                    0\n",
      "30                            [New York City, New York]\n",
      "31    [Avonlea, Prince Edward Island, Prince Edward ...\n",
      "32    [Jackson, Mississippi, Mississippi, The United...\n",
      "33                                                    0\n",
      "34                       [The United States of America]\n",
      "35    [New York City, New York, Montauk, New York, N...\n",
      "36             [Salinas Valley, California, California]\n",
      "37                        [Chicago, Illinois, Illinois]\n",
      "38    [Transylvania, Budapest, Whitby, Yorkshire, En...\n",
      "39                        [New Mexico, London, England]\n",
      "40                                            [Macondo]\n",
      "41    [New York City, New York, Agerstown, Pennsylva...\n",
      "42                                                    0\n",
      "43                          [Afghanistan, Kabul, Herat]\n",
      "44        [Yorkshire, England, England, United Kingdom]\n",
      "45                          [The Lands of Ice and Fire]\n",
      "46                                        [Connecticut]\n",
      "47                                    [Tulsa, Oklahoma]\n",
      "48    [The United States of America, St. Petersburg,...\n",
      "49    [Philadelphia, Pennsylvania, Pennsylvania, The...\n",
      "Name: places_new, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# df2 = df2.replace({'places': {'nan': 0}})\n",
    "df2 = df2.replace({'places': {np.nan: 0}})\n",
    "# print(df2['places'])\n",
    "\n",
    "dictt = []\n",
    "for i in df2.index:\n",
    "    if df2.loc[i, \"places\"] == 0:\n",
    "        dictt.append(0)\n",
    "    else:\n",
    "        dictt.append( ast.literal_eval(df2.loc[i, \"places\"]) )\n",
    "\n",
    "df2['places_new'] = dictt\n",
    "print(df2['places_new'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df2.groupby('places').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6e128dd2cf9bb12ecf94668e33e1546608d302a4f44df6f6afa2b8f73a532e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Strive': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
